{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import TrajectoryDataset\n",
    "from lightly.models.modules.heads import VICRegProjectionHead\n",
    "from utils import save_model, compute_mean_and_std, get_byol_transforms, get_vicreg_loss\n",
    "from utils import criterion as VICReg_criterion\n",
    "from tqdm import tqdm\n",
    "from models import JEPAModel\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 1024\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "use_expander = False\n",
    "batch_size = 16 \n",
    "\n",
    "dataset_directory = \"./dataset\"\n",
    "states_filename = \"states.npy\"\n",
    "actions_filename = \"actions.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_joint(model, dataloader, criterion_encoder, criterion_pred, \n",
    "                optimizer, transformation1, transformation2, \n",
    "                device, epochs=10, use_expander=False):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # clipping the gradient to handle gradient explosions in LSTM\n",
    "    max_val = 5.0\n",
    "    for param in model.predictor.parameters():\n",
    "        if param.grad is not None:\n",
    "            param.grad.data = torch.clamp(param.grad.data, -max_val, max_val)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batch\"):\n",
    "            state, action = batch\n",
    "            state, action = state.to(device), action.to(device)\n",
    "            B, L, D = state.shape[0], action.shape[1], model.predictor.hidden_size\n",
    "\n",
    "            loss, loss1, loss2, loss3 = 0, 0, 0, 0\n",
    "\n",
    "            o = state[:, 0, :, :, :]\n",
    "            c0 = torch.zeros((B, D)).to(device)\n",
    "            model.set_predictor(o, c0, use_expander)\n",
    "\n",
    "            # compute loss1\n",
    "            loss1 = get_vicreg_loss(model, o, transformation1, transformation2, \n",
    "                                     criterion_encoder)\n",
    "            for i in range(L):\n",
    "                # inference of encoder(next state) and predictor(action) \n",
    "                sy_hat, (sy_enc, sy_exp) = model(action[:, i, :], state[:, i+1, :, :, :])\n",
    "                sy = sy_exp if use_expander else sy_enc\n",
    "\n",
    "                # compute loss2 (distance btw sy and sy_hat)\n",
    "                loss2 += criterion_pred(sy_hat, sy)\n",
    "                # vic_reg loss for encoder (for encoding next state)\n",
    "                loss3 += get_vicreg_loss(model, state[:, i, :, :, :], \n",
    "                                          transformation1, transformation2, \n",
    "                                          criterion_encoder) \n",
    "            \n",
    "            # adding all loss and doing back propagation\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch: {epoch}, total_loss: {total_loss}, the avg loss = {total_loss/len(dataloader)}\")\n",
    "        save_model(model, epoch, file_name=\"join_model\")\n",
    "\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data_points 63\n",
      "Shape of state: torch.Size([16, 17, 2, 65, 65])\n",
      "Shape of action: torch.Size([16, 16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/miniconda3/envs/ml/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "dataset = TrajectoryDataset(\n",
    "    data_dir = dataset_directory,\n",
    "    states_filename = states_filename,\n",
    "    actions_filename = actions_filename,\n",
    "    s_transform = None,\n",
    "    a_transform = None,\n",
    "    length = 1000 \n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "first_datapoint = next(iter(dataloader))\n",
    "state, action = first_datapoint\n",
    "print(f\"Number of data_points {len(dataloader)}\")\n",
    "print(f\"Shape of state: {state.shape}\")\n",
    "print(f\"Shape of action: {action.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = compute_mean_and_std(dataloader, is_channelsize3=False)\n",
    "transformation1, transformation2 = get_byol_transforms(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:30<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, total_loss: 41872.14825439453, the avg loss = 664.6372738792783\n",
      "Model saved to checkpoints/join_model_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:29<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total_loss: 40472.96569824219, the avg loss = 642.4280269562252\n",
      "Model saved to checkpoints/join_model_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:29<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, total_loss: 39556.43377685547, the avg loss = 627.8799012199281\n",
      "Model saved to checkpoints/join_model_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:29<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, total_loss: 39138.952575683594, the avg loss = 621.2532154870412\n",
      "Model saved to checkpoints/join_model_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:30<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, total_loss: 38889.23504638672, the avg loss = 617.2894451807416\n",
      "Model saved to checkpoints/join_model_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:30<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, total_loss: 38840.490173339844, the avg loss = 616.5157170371403\n",
      "Model saved to checkpoints/join_model_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:30<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, total_loss: 38448.87774658203, the avg loss = 610.2996467711433\n",
      "Model saved to checkpoints/join_model_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:31<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, total_loss: 38130.42510986328, the avg loss = 605.2448430137028\n",
      "Model saved to checkpoints/join_model_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:31<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, total_loss: 37982.05352783203, the avg loss = 602.8897385370163\n",
      "Model saved to checkpoints/join_model_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 63/63 [00:32<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, total_loss: 37877.866455078125, the avg loss = 601.2359754774305\n",
      "Model saved to checkpoints/join_model_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JEPAModel(\n",
       "  (encoder): VICRegModel(\n",
       "    (backbone): SimpleEncoder(\n",
       "      (conv1): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (pool1): MaxPool2d(kernel_size=(5, 5), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (pool2): MaxPool2d(kernel_size=(5, 5), stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "      (fc1): Linear(in_features=432, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    )\n",
       "    (projection_head): VICRegProjectionHead(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): Predictor(\n",
       "    (lstm_cell): LSTMCell(2, 1024)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = JEPAModel(embed_dim, 2)\n",
    "\n",
    "joint_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1.5e-4)\n",
    "# joint_optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion_predictor = nn.MSELoss()\n",
    "criterion_encoder = VICReg_criterion\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_joint(model, dataloader, criterion_encoder, criterion_predictor, \n",
    "            joint_optimizer, transformation1, transformation2, device,\n",
    "            epochs=epochs, use_expander=use_expander)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
