{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import TrajectoryDataset\n",
    "from lightly.models.modules.heads import VICRegProjectionHead\n",
    "from utils import save_model, compute_mean_and_std, get_byol_transforms, get_vicreg_loss\n",
    "from utils import criterion as VICReg_criterion\n",
    "from tqdm import tqdm\n",
    "from models import JEPAModelv2\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 432 \n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "use_expander = False\n",
    "batch_size = 16 \n",
    "\n",
    "dataset_directory = \"./dataset\"\n",
    "states_filename = \"states.npy\"\n",
    "actions_filename = \"actions.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_joint(model, dataloader, criterion_encoder, criterion_pred, \n",
    "                optimizer, transformation1, transformation2, \n",
    "                device, epochs=10, use_expander=False):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batch\"):\n",
    "            state, action = batch\n",
    "            state, action = state.to(device), action.to(device)\n",
    "            B, L, D = state.shape[0], action.shape[1], model.repr_dim\n",
    "\n",
    "            loss, loss1, loss2, loss3 = 0, 0, 0, 0\n",
    "\n",
    "            o = state[:, 0, :, :, :]\n",
    "            model.set_init_embedding(o)\n",
    "\n",
    "            for i in range(L):\n",
    "                # inference of encoder(next state) and predictor(action) \n",
    "                sy_hat, sy = model(action[:, i, :], state[:, i+1, :, :, :])\n",
    "\n",
    "                # compute loss2 (distance btw sy and sy_hat)\n",
    "                loss2 += criterion_pred(sy_hat, sy)\n",
    "            \n",
    "            # adding all loss and doing back propagation\n",
    "            loss = loss2 \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch: {epoch}, total_loss: {total_loss}, the avg loss = {total_loss/len(dataloader)}\")\n",
    "        save_model(model, epoch, file_name=\"join_modelv2\")\n",
    "\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data_points 125\n",
      "Shape of state: torch.Size([16, 17, 2, 65, 65])\n",
      "Shape of action: torch.Size([16, 16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/miniconda3/envs/ml/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "dataset = TrajectoryDataset(\n",
    "    data_dir = dataset_directory,\n",
    "    states_filename = states_filename,\n",
    "    actions_filename = actions_filename,\n",
    "    s_transform = None,\n",
    "    a_transform = None,\n",
    "    length = 2000 \n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "first_datapoint = next(iter(dataloader))\n",
    "state, action = first_datapoint\n",
    "print(f\"Number of data_points {len(dataloader)}\")\n",
    "print(f\"Shape of state: {state.shape}\")\n",
    "print(f\"Shape of action: {action.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = compute_mean_and_std(dataloader, is_channelsize3=False)\n",
    "transformation1, transformation2 = get_byol_transforms(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:11<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, total_loss: 39.8578193967478, the avg loss = 0.3188625551739824\n",
      "Model saved to checkpoints/join_modelv2_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:10<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total_loss: 0.006402654329576762, the avg loss = 5.1221234636614096e-05\n",
      "Model saved to checkpoints/join_modelv2_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:14<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, total_loss: 0.002673478740689461, the avg loss = 2.1387829925515688e-05\n",
      "Model saved to checkpoints/join_modelv2_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:12<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, total_loss: 0.001401989046826202, the avg loss = 1.1215912374609616e-05\n",
      "Model saved to checkpoints/join_modelv2_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:13<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, total_loss: 0.0008633216498310503, the avg loss = 6.9065731986484025e-06\n",
      "Model saved to checkpoints/join_modelv2_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:10<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, total_loss: 0.0006030483618815197, the avg loss = 4.824386895052157e-06\n",
      "Model saved to checkpoints/join_modelv2_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:11<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, total_loss: 0.0004600449135523377, the avg loss = 3.6803593084187012e-06\n",
      "Model saved to checkpoints/join_modelv2_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:08<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, total_loss: 0.00037129764655219333, the avg loss = 2.9703811724175464e-06\n",
      "Model saved to checkpoints/join_modelv2_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:08<00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, total_loss: 0.0003095641968684504, the avg loss = 2.476513574947603e-06\n",
      "Model saved to checkpoints/join_modelv2_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:08<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, total_loss: 0.0002638307944380358, the avg loss = 2.1106463555042864e-06\n",
      "Model saved to checkpoints/join_modelv2_9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:08<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, total_loss: 0.00022779921721394203, the avg loss = 1.8223937377115362e-06\n",
      "Model saved to checkpoints/join_modelv2_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:07<00:00, 16.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, total_loss: 0.00019860146608152718, the avg loss = 1.5888117286522174e-06\n",
      "Model saved to checkpoints/join_modelv2_11.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:07<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, total_loss: 0.00017412097747637745, the avg loss = 1.3929678198110195e-06\n",
      "Model saved to checkpoints/join_modelv2_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:06<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, total_loss: 0.00015350115984347212, the avg loss = 1.228009278747777e-06\n",
      "Model saved to checkpoints/join_modelv2_13.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:07<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, total_loss: 0.00013581261953277135, the avg loss = 1.0865009562621709e-06\n",
      "Model saved to checkpoints/join_modelv2_14.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:06<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, total_loss: 0.0001204506979775033, the avg loss = 9.636055838200264e-07\n",
      "Model saved to checkpoints/join_modelv2_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:06<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, total_loss: 0.00010720207785652747, the avg loss = 8.576166228522198e-07\n",
      "Model saved to checkpoints/join_modelv2_16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:07<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, total_loss: 9.543350824969821e-05, the avg loss = 7.634680659975856e-07\n",
      "Model saved to checkpoints/join_modelv2_17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:07<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, total_loss: 8.519333783851835e-05, the avg loss = 6.815467027081468e-07\n",
      "Model saved to checkpoints/join_modelv2_18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 125/125 [00:07<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, total_loss: 7.620421030196667e-05, the avg loss = 6.096336824157334e-07\n",
      "Model saved to checkpoints/join_modelv2_19.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JEPAModelv2(\n",
       "  (encoder): SimpleEncoderv2(\n",
       "    (conv1): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (pool1): MaxPool2d(kernel_size=(5, 5), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pool2): MaxPool2d(kernel_size=(5, 5), stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc1): Linear(in_features=432, out_features=1024, bias=True)\n",
       "    (fc2): Linear(in_features=1024, out_features=432, bias=True)\n",
       "  )\n",
       "  (predictor): Predictorv2(\n",
       "    (linear1): Linear(in_features=434, out_features=2048, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=2048, out_features=432, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = JEPAModelv2(embed_dim, 2048, 2, 2)\n",
    "\n",
    "# joint_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1.5e-4)\n",
    "joint_optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion_predictor = nn.MSELoss()\n",
    "criterion_encoder = VICReg_criterion\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_joint(model, dataloader, criterion_encoder, criterion_predictor, \n",
    "            joint_optimizer, transformation1, transformation2, device,\n",
    "            epochs=epochs, use_expander=use_expander)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
